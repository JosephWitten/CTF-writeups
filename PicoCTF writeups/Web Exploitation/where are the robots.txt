1) the title suggests we visit robots.txt, robots.txt is a file that most sites have which tell web crawlers not to index certain pages, this is often where hidden locations (in bad applications) can be found
2) to do so add "/robots.txt" to the end of the URL
3) we see "Disallow /e0779.html", so we should visit this page using the same method as the robots.txt.
4) going to this url reveals the flag